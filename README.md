# Activity Monitoring & Classification System

PrÃ©diction du churn client bancaire grÃ¢ce Ã  XGBoost optimisÃ© avec feature engineering et calibration du seuil pour maximiser le F1-score.

## ğŸ“‚ Description

Ce projet suit une approche progressive pour amÃ©liorer les performances dâ€™un modÃ¨le de classification sur un dataset bancaire :  

1. Analyse exploratoire des donnÃ©es (EDA) pour dÃ©tecter doublons, valeurs manquantes, outliers et dÃ©sÃ©quilibre des classes.  
2. PrÃ©paration des donnÃ©es : nettoyage, encodage des variables catÃ©gorielles, crÃ©ation de nouvelles features (`AgeGroup`, `LowProducts`, `Age_Products`).  
3. EntraÃ®nement et Ã©valuation de modÃ¨les : RandomForest et XGBoost, avec optimisation des hyperparamÃ¨tres et calibration du seuil pour maximiser le F1-score sur la classe minoritaire.  

Le modÃ¨le final XGBoost atteint un **F1-score de 0.766** sur le jeu de validation aprÃ¨s optimisation.

## ğŸ” Structure du projet

```

.
â”œâ”€â”€ notebooks/                # Notebooks dâ€™analyse et dâ€™entraÃ®nement
â”œâ”€â”€ data/                     # Jeux de donnÃ©es (train/test)
â”œâ”€â”€ scripts/                  # Scripts Python pour feature engineering et entraÃ®nement
â”œâ”€â”€ README.md                 # Documentation du projet
â””â”€â”€ requirements.txt          # DÃ©pendances Python

````

## ğŸ› ï¸ Installation

1. Cloner le dÃ©pÃ´t :  
```bash
git clone https://github.com/AidanAcartis/taskMonitor.git
cd taskMonitor
````

2. CrÃ©er un environnement conda et installer les dÃ©pendances :

```bash
conda create -n churn_env python=3.12
conda activate churn_env
pip install -r requirements.txt
```

3. Lancer les notebooks ou scripts pour reproduire les analyses et lâ€™entraÃ®nement du modÃ¨le.

## ğŸ“Š MÃ©thodologie

### 1. Analyse des donnÃ©es

* VÃ©rification de la qualitÃ© des donnÃ©es (doublons, NaN, erreurs de labels, outliers)
* Ã‰tude des corrÃ©lations et du pouvoir prÃ©dictif des variables
* Analyse du dÃ©sÃ©quilibre des classes

### 2. PrÃ©paration des donnÃ©es

* Suppression des colonnes peu informatives (`Satisfaction Score`, `RowNumber`, `Surname`, `Point Earned`)
* Encodage des variables catÃ©gorielles avec OneHotEncoder
* CrÃ©ation de nouvelles features :

  * `AgeGroup` : tranche dâ€™Ã¢ge
  * `LowProducts` : flag pour clients ayant un seul produit
  * `Age_Products` : interaction Ã¢ge Ã— nombre de produits

### 3. ModÃ©lisation

* RandomForestClassifier : test avec/sans feature `Complain`, SMOTE/ADASYN
* XGBoost : hyperparameter tuning avec RandomizedSearchCV
* Calibration du seuil pour maximiser le F1-score de la classe minoritaire

## ğŸ“ˆ RÃ©sultats

* **RandomForest avec Complain** : F1 â‰ˆ 0.994 (biais dÃ» Ã  la fuite de donnÃ©es)
* **RandomForest sans Complain** : F1 â‰ˆ 0.59
* **RandomForest + SMOTE** : F1 â‰ˆ 0.55
* **XGBoost final** : F1 â‰ˆ 0.766 (avec hyperparameter tuning et feature engineering)

## âš™ï¸ Technologies

* Python 3.12
* Pandas, NumPy, Matplotlib, Seaborn
* Scikit-learn, Imbalanced-learn
* XGBoost

## ğŸ“ Lien GitHub

[Voir le dÃ©pÃ´t sur GitHub](https://github.com/AidanAcartis/taskMonitor)

## ğŸ”— License

MIT License
